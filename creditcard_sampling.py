# -*- coding: utf-8 -*-
"""CreditCard_Sampling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12fHLL0KeqfSZp2oH7Lbfhuh3n1duipj3
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.svm import SVC
from imblearn.over_sampling import SMOTE
from sklearn.utils import resample
from sklearn.cluster import KMeans
from math import ceil

# Load data
df = pd.read_csv("Creditcard_data.csv")

# Features and target variable
X = df.drop(columns=["Class", "Time"])
y = df["Class"]

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the models
models = {
    'Logistic Regression': LogisticRegression(),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'XGBoost': XGBClassifier(),
    'SVM': SVC()
}

# Function to calculate sample size using the sample size detection formula
def calculate_sample_size(population_size, confidence_level=0.95, margin_of_error=0.05):
    Z = 1.96  # Z-score for 95% confidence level
    p = 0.5  # Estimated proportion (maximum variability)
    q = 1 - p
    E = margin_of_error

    # Sample size formula: n = (Z^2 * p * q) / E^2
    n = (Z**2 * p * q) / (E**2)
    sample_size = ceil(n)  # Round up to the nearest integer
    return sample_size

# Calculate sample size for the dataset
population_size = len(df)
sample_size = calculate_sample_size(population_size)

# Function for Stratified Sampling
def stratified_sampling(X, y, sample_size):
    return resample(X, y, n_samples=sample_size, stratify=y, random_state=42)

# Function for Random Sampling
def random_sampling(X, y, sample_size):
    return resample(X, y, n_samples=sample_size, random_state=42)

# Function for Systematic Sampling
def systematic_sampling(X, y, sample_size):
    step = len(X) // sample_size
    indices = np.arange(0, len(X), step)
    return X[indices], y.iloc[indices]

# Function for Cluster Sampling
def cluster_sampling(X, y, sample_size, n_clusters=2):
    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X)
    cluster_labels = kmeans.labels_
    selected_clusters = np.random.choice(np.unique(cluster_labels), size=n_clusters, replace=False)
    selected_indices = np.isin(cluster_labels, selected_clusters)
    return X[selected_indices], y[selected_indices]

# Apply SMOTE (Synthetic Minority Over-sampling)
def apply_smote(X, y):
    smote = SMOTE(random_state=42)
    return smote.fit_resample(X, y)

# Sampling techniques
sampling_techniques = {
    'Stratified Sampling': stratified_sampling,
    'Random Sampling': random_sampling,
    'Systematic Sampling': systematic_sampling,
    'Cluster Sampling': cluster_sampling,
    'SMOTE': apply_smote
}

# Function to evaluate models with different sampling techniques
def evaluate_model_sampling(X_train, y_train, X_test, y_test):
    results = {}

    for sampling_name, sampler in sampling_techniques.items():
        # Apply the sampling technique
        if sampling_name != 'SMOTE':
            X_resampled, y_resampled = sampler(X_train, y_train, sample_size)
        else:
            X_resampled, y_resampled = sampler(X_train, y_train)

        model_results = {}
        for model_name, model in models.items():
            # Train the model
            model.fit(X_resampled, y_resampled)

            # Predict on the test set
            y_pred = model.predict(X_test)

            # Calculate accuracy
            accuracy = accuracy_score(y_test, y_pred)
            model_results[model_name] = accuracy

        results[sampling_name] = model_results
    return results

# Evaluate models with different sampling techniques
results = evaluate_model_sampling(X_train, y_train, X_test, y_test)

# Display results
for sampling_name, model_results in results.items():
    print(f"Results for {sampling_name}:")
    for model_name, accuracy in model_results.items():
        print(f"{model_name}: {accuracy:.4f}")
    print("-" * 50)